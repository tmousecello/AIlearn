# AI筆記

## AI GO 的課
### 機器學習
映射的概念  
把一個資料變成結果  
方法:監督式學習、非監督式學習  
語音->文字(語音識別)  
人臉->身分(人臉辨識)  
計算力重點是GPU  
資料須注意法規，例如歐盟的個人隱私法案  
奧卡姆剃刀原則:相同效果的前提下，模型越簡單越好

### 神經網路
參考人類的大腦  
人腦:樹突收集訊號->神經核匯總轉換->傳遞訊號  
捲積神經網路:模仿人類視網膜(多用於判別圖片 可作中文分析)  
遞迴神經網路:模仿人類記憶(多用於語言建模 缺點:無法平行運算)  
強化學習:模仿人類適應能力(結果制，做對給獎勵，做錯給處罰 紅蘿蔔+棍子)  

### 深度學習
重點是表徵學習  
讓機器以更像人腦的方式思考  
特徵->規則->預測  
機器可以把人類無法想像的規則找出，不受人的思考制約  
會混入一點髒數據  
向量方式表現(所以G0PU算起來才強)  
多維壓縮至低維,找出最近的位置  
微分、向量、矩陣運算  
機器較難判斷模糊的東西  
人腦可以建立多種規則(特徵點)  
機器自己找出多種特徵、規則  
缺點:機器需要大量範例  
奧卡姆剃刀原則不一定成立  

### 優點
機器學習過的一定會記得  
機器可以在短時間內處理大量資料


### 缺點
機器現在不會真的思考  
機器不懂常識，只懂得輸入輸出間的關聯  
機器很難處理特例  
機器需要明確結果與"標準化"輸入才能運作  
AI產品不能放在外面讓它不斷自己學習，不然很可能會學壞    
一個運算模型一次只能做一件事  
無法自由切換切入問題角度，切換模型需要人類定義解決方法  
AI無法做沒有標準答案的判斷  
容易學壞(ex:性別、種族歧視)  

### 機器視覺
希望建立(機器可讀)像素訊號與人類視覺的映射關係  
人看到的是狗，機器看到的是一堆數據  
通常尺寸是224*224  
輸入需要嚴格定義與固定  
需要基於標註(標註需標準化)  
需要一點一點的累積  
標註很重要  
把人類對世界的了解透過標註讓機器理解  

### 對抗生成
Generative Adversarial Network,GAN  
透過彼此競爭互相優化  
一個模型負責製造假照片  
另一個負責辨識  
再用強化學習(獎勵&懲罰)  
機器容易被騙(對抗式攻擊(資安部分))   

### 應用
AI可以進行藝術設計(找尋最相關結構進行風格轉移)  
可以識別服裝並且了解消費習慣   
可以用一些人無法辨識的信號進行處理  
ex:用wifi信號強弱判定牆後人的行動  
GAN可以做美容軟體  
馬賽克還原  
自然語言理解  

### 訓練數據
訓練->推理
數據要小心規則與巧合  
定義要清楚  
所以訓練數據跟測試數據要分開  
測試數據要分時間內測試和時間外測試(訓練結果驗證新的數據)  
訓練需要大量算力(GPU&TPU)  
邊緣運算-由於推理不像訓練需要大量算力，讓推理在邊緣端(效能較低裝置或用戶端?)處理


### 張量
scalar-標量:純數值  
vector-向量:一維數據  
matirx-矩陣:二維數據  
tensor-張量:N維數據(除了scalar)  
在深度學習的三維空間表示:C(通道數)*H(高)*W(寬)，高一定在寬前面(按字母順序)  
tensor flow比較特別，是H*W*C  
png是四維(要加上透明度)  
顏色排列:tensorflow是RGB(按人類習慣)，opencv是BGR(按字母順序)  
顏色越淺，數字越大(以光強度來理解)  
tensorflow會比較慢  
tensorflow的標準比較特別，要注意
python套件讀取圖片需要注意RGB、HWC的問題  




## asus的課

### 描述AI的對照
人類怎麼學新知識->電腦就怎麼學(回歸與分類)  
如何以經驗導出結論(邏輯、推理)  
如何以經驗處理新事物的刺激  

### 訓練階段
大量資料->找出特徵、給予標籤(標註)->訓練模型  
可利用已有的model改良  
遊戲截圖->標註距離->得到結果  
可以用雲端服務訓練  
teachablemachine.withgoogle.com 可體驗  

### 推論階段
由之前訓練的資料判斷，產出結果  
ex:人臉識別(即時運算)  
市面上有推論用的加速卡  
可能有現成的AI模型  




















