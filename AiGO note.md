# AI筆記

kaggle 是個資料學習的網站，上面有比賽
RS compoments 東西比較便宜
## AI GO 的課
### 機器學習
映射的概念  
把一個資料變成結果  
方法:監督式學習、非監督式學習  
語音->文字(語音識別)  
人臉->身分(人臉辨識)  
計算力重點是GPU  
資料須注意法規，例如歐盟的個人隱私法案  
奧卡姆剃刀原則:相同效果的前提下，模型越簡單越好  
要多注意新的技術發展  
要清楚問題  

### 神經網路
參考人類的大腦  
人腦:樹突收集訊號->神經核匯總轉換->傳遞訊號  
捲積神經網路:模仿人類視網膜(多用於判別圖片 可作中文分析)  
遞迴神經網路:模仿人類記憶(多用於語言建模 缺點:無法平行運算)  
強化學習:模仿人類適應能力(結果制，做對給獎勵，做錯給處罰 紅蘿蔔+棍子)  
大腦的稀疏姓:大腦面對刺激一次只會觸發一小部分的腦  
心理的距離跟數學上的距離不一樣  
人類的大腦活化函數是S型，中間那段才是線性關係，對極值較無感  

### 深度學習
重點是表徵學習  
讓機器以更像人腦的方式思考  
多層抽取特徵
特徵->規則->預測  
機器可以把人類無法想像的規則找出，不受人的思考制約  
會混入一點髒數據  
向量方式表現(所以G0PU算起來才強)  
多維壓縮至低維,找出最近的位置  
微分、向量、矩陣運算  
機器較難判斷模糊的東西  
人腦可以建立多種規則(特徵點)  
機器自己找出多種特徵、規則  
奧卡姆剃刀原則不一定成立  
Denoise Auto-Encoder:  
搞髒的圖->變成乾淨的圖  
機器學會分辨正確訊息跟噪音  
模仿人腦的S曲線，思考會更接近人

### 優點 
機器學習過的一定會記得  
機器可以在短時間內處理大量資料  


### 缺點
機器現在不會真的思考  
機器不懂常識，只懂得輸入輸出間的關聯  
機器很難處理特例  
機器需要明確結果與"標準化"輸入才能運作  
AI產品不能放在外面讓它不斷自己學習，不然很可能會學壞    
一個運算模型一次只能做一件事  
無法自由切換切入問題角度，切換模型需要人類定義解決方法  
AI無法做沒有標準答案的判斷  
容易學壞(ex:性別、種族歧視)  

### 機器視覺
希望建立(機器可讀)像素訊號與人類視覺的映射關係  
人看到的是狗，機器看到的是一堆數據  
通常尺寸是224*224  
輸入需要嚴格定義與固定  
需要基於標註(標註需標準化)  
需要一點一點的累積  
標註很重要  
把人類對世界的了解透過標註讓機器理解  

### 對抗生成
Generative Adversarial Network,GAN  
透過彼此競爭互相優化  
一個模型負責製造假照片  
另一個負責辨識  
再用強化學習(獎勵&懲罰)  
機器容易被騙(對抗式攻擊(資安部分))   

### 應用
AI可以進行藝術設計(找尋最相關結構進行風格轉移)  
可以識別服裝並且了解消費習慣   
可以用一些人無法辨識的信號進行處理  
ex:用wifi信號強弱判定牆後人的行動  
GAN可以做美容軟體  
馬賽克還原  
自然語言理解  

### 訓練數據
訓練->推理
數據要小心規則與巧合  
定義要清楚  
所以訓練數據跟測試數據要分開  
測試數據要分時間內測試和時間外測試(訓練結果驗證新的數據)  
訓練需要大量算力(GPU&TPU)  
邊緣運算-由於推理不像訓練需要大量算力，讓推理在邊緣端(效能較低裝置或用戶端?)處理  
欠擬合(underfitting):模型效度太低；過擬合(overfitting):模型效度太好，機器背下答案  
過擬合可能很難分辨，造成機器學好的假象  
萬能建模定理:神經網路中，只要一層足夠量的隱藏層，就可以模擬任何函數  
數據量不夠多，機器就會背答案  
需要以另一組數據檢視是否過擬合  
使用數據增強(搞髒數據):稍微改變數據樣式  EX:灰度變化、水平翻轉、旋轉、裁切、調色  
加入丟棄機制，防止模型用過度複雜的結構進行學習  
人類的視覺空間可交換性:一隻貓不會從地板跑到屋頂上，人就把它看成一隻狗  
訓練機器從缺失的數據判斷  
學好open cv  
數據要正規化(可能標準化?)  
深度學習多以0為中間(數據減掉平均值)  
RGB的正規化通常是減127.5(256的一半)再除以127.5(把數據範圍縮小到-1到1之間)  
把數據整成常態分布，會接近人腦的S曲線微分後的樣子  
但真實世界大多不是常態分布  

### 數據標註
辨識模型標註方法一:把各類數據放在對應資料夾  
標註方法:LabelMe(標籤框選位置)  
多用打方框，因標註容易  
框要在四個極端點  
要避免機器誤解，需要清楚線索  
人臉規範是68個關鍵點  


### 張量
scalar-標量:純數值  
vector-向量:一維數據  
matirx-矩陣:二維數據  
tensor-張量:N維數據(除了scalar)  
在深度學習的三維空間表示:C(通道數)*H(高)*W(寬)，高一定在寬前面(按字母順序)  
tensor flow比較特別，是H*W*C  
png是四維(要加上透明度)  
顏色排列:tensorflow是RGB(按人類習慣)，opencv是BGR(按字母順序)  
顏色越淺，數字越大(以光強度來理解)  
tensorflow會比較慢  
tensorflow的標準比較特別，要注意
python套件讀取圖片需要注意RGB、HWC的問題  

### 缺失數據
缺失數據處理重要性逐漸降低  
因為用問卷問的資料不一定正確，人可能因面子或其他原因撒謊，或實際使用的不是填問卷的人  
現在以行為數據居多  
圖片若太小，可以外圍用0填滿，或縮放
以用0或隨機亂數滿足張量的固定大小
深度學習可能會人為刻意製造缺失數據(髒數據)

### 遷移學習
站在大佬的肩膀上  
預訓練過的機器比沒訓練過的機器更快  
灌輸機器嘗試的概念(讓機器了解通則)  
預訓練要有龐大數據  
imagenet有預訓練模型  
pytorch可用torchvision  
其他可以用onnx   
保留前面權重，處理後面連接層  
可以用較少數據訓練  
如果數據規模較多，可以更改較近的權重  
如果數據規模極大，可以優化較前面的權重  
數據量小，條的範圍小  

## asus的課

### 描述AI的對照
人類怎麼學新知識->電腦就怎麼學(回歸與分類)  
如何以經驗導出結論(邏輯、推理)  
如何以經驗處理新事物的刺激  

### 訓練階段
大量資料->找出特徵、給予標籤(標註)->訓練模型  
可利用已有的model改良  
遊戲截圖->標註距離->得到結果  
可以用雲端服務訓練  
teachablemachine.withgoogle.com 可體驗  

### 推論階段
由之前訓練的資料判斷，產出結果  
ex:人臉識別(即時運算)  
市面上有推論用的加速卡  
可能有現成的AI模型  

## 鴻海的課

### 把問題化為函數
前面說的映射  
按圖索驥找到答案  
因為函數是一對一，不行一對多，所以問題要定義清楚答案(此說法本人存疑)  
精確輸入->輸出  
輸入輸出要把變成電腦能讀懂的資料形式  
輸入輸出維度必須固定  
函數:定義域對值域(參考小黃本的集合論講義)  

###用AI解決問題的步驟
1.先有問題  
有好的問題很重要  
但有思考一下這問題是不是直接寫程式更方便  
2.把問題變函數的形式  
讓機器看得懂  
3.找訓練資料跟測試資料  
需要大量  
4.用人工智慧的一些方法(例如深度學習、神經網路、機器學習)設計模型  
通常有參數要調整  
5.訓練機器  
損失函數: 計算機器學習到的函數跟訓練資料差異多少的函數  

### AI 和人的差別
核心技術大概1980就有  
之前人工智慧失敗原因:  
1.沒有夠好的軟體  
2.電腦算力不足  
3.數據量不夠大  
AI做不到的事:  
1.電腦無法提出問題  
2.電腦無法依常識判斷對錯
3.電腦無法自動產生人工智慧  

### 機器學習演算法
分類問題:把未知訊息歸納進已知訊息，重點在新資料和以分類資料相互比對(已有名確分類，通常為監督式學習)  
分群問題:沒有明確分類，透過二者不同的特徵區分(未確定分類之前，通常為非監督式學習)  
  
線性分類器:統計的方法，將數據畫成平面圖，找到一線可分割，分析關係  
超平面: 在n為空間中，找到一個n-1維的超平面來分割  
支持向量機(SVM):分類問題中的一種工具，把線性分類器平行移動，找出線性分類器的最大寬度(可移動、改變斜率)  
核函數(kernel funtion):支持向量機的分類函數，可以由數學函數轉換成非線性函數，支持向量機可以用核函數的轉換，簡化分類困難度  
  
決策數:每次針對一個特徵來分類，可以用二元樹(或多元樹)的方式畫出來  
資訊獲利:找出以哪種特徵進行分類的整體正確率比較高，通常經由持續迭代的方式測試每個規則的正確率  
  
KNN(K-nearest neighbor):監督式學習分類演算法，利用兩點的特徵距離遠近，判斷新的資料比較想哪一類  
K-平均演算法(k-means clustering):非監督式學習分群演算法，找出每個群的重心。先隨機分群->找出群的重心->計算和重心的距離->離另一重心較近的點更新到另一群->再次計算

### 基本神經網路架構
三大架構:標準神經網路(NN)、卷積神經網路(CNN)、遞迴神經網路(RNN)  
NN:萬用工具，最常搭配其他神經網路的模式  
CNN:適合處理圖片影片  
RNN:適合處理需要有順序(有記憶)的資料
人工神經網路(ANN簡稱NN):源自神經元傳導機制，讓電腦具備學習及記憶能力 
輸入層:接受刺激(訊號)的神經元，像是受器，不同輸入會觸發不同神經元  
隱藏層:不直接與外部接觸，像是中樞神經，接受輸入層或其他隱藏層中的訊息，對受到的訊息進行處理，再傳到其他隱藏層或輸出層  
輸出層:收到訊息後特定的神經元會做出反應，像是動器  
深度學習:隱藏層比較多，通常為三層或三層以上
不同神經網路架構常常混用  
可是為迴歸分析的推廣  

### NN
全連結神經網路(fully connected neural network):任一層的一個神經元都會和下一層每個神經元相連，每個隱藏層神經元會接受到上一層所有的訊息，也稱為標準神經網路  
前饋神經網路(feedforward neural network):輸入層接受到輸入後，一層一層往後傳遞，這樣每個神經元的動作基本都會是一樣的  
計算公式:輸出=<math xmlns='http://www.w3.org/1998/Math/MathML'> <mtable columnalign='left'> <mtr> <mtd> <mo> &#x00B7; <!-- middle dot --> </mo> </mtd> </mtr> <mtr> <mtd> <msub> <mrow> <mi> &#x03C6; <!-- greek small letter phi --> </mi> </mrow> <mrow> <mn> 1 </mn> </mrow> </msub> <munderover> <mrow> <mo> &#x2211; <!-- n-ary summation --> </mo> </mrow> <mrow> <mi> i </mi> <mo> = </mo> <mn> 1 </mn> </mrow> <mrow> <mn> 3 </mn> </mrow> </munderover> <msub> <mrow> <mi> w </mi> </mrow> <mrow> <mi> i </mi> </mrow> </msub> <msub> <mrow> <mi> x </mi> </mrow> <mrow> <mi> i </mi> </mrow> </msub> <mo> + </mo> <mi> b </mi> <mi> i </mi> </mtd> </mtr> </mtable> </math>  
三應該為神經元數量，i應該為層數，wi:權重、bi:偏值(bias)、φ:激勵函數(通常為非線性)，可調整參數:權重與偏值，一次調整會調整一層神經元  
調整方法:計算損失函數，找出一組參數，使損失函數為最小  
梯度下降法(喔幹微積分的部分):損失函數的移動方向和梯度方向相反，所以要讓損失函數最小，就往梯度的反方向走，因為調整順序是由後面一層一層往前調，所以又被稱為反向傳播法(backpropagation)  

### CNN
由卷積層(convolution layer)加池化層(pooling layer)組成  
卷積層:透過過濾器找特徵  
池化層:降低特定特徵的強度  
架構:輸入->(卷積層->池化層)*n->全連結層->輸出  
可以做多次卷積池化，甚至可以只卷積不池化，最後常接上一層或多層NN  

###RNN
用隱藏層的方式儲存前一次的輸出  
記憶方式:把前一次的輸出和這次的輸入一起處理再輸出  
適合和時間有關或需參考前後文或有順序的資料  
可以給RNN個開頭，讓他完成剩下的  
適合做聊天機器人  

### 電腦眼中的圖像
對電腦而言，圖片是由項素組成的矩陣  
解析度1024*768 指的是有1024行，768列  
灰階圖片:只有明暗不同，只需要一個數字就可以表現，通常0是最暗(純黑)，255最亮(純白)
彩色圖片:RGB各由0~255的明暗程度疊加起來  

###空間濾波
可先縮放、旋轉進行預處理，增加照片數量  
透過濾波器與原圖進行捲機運算得到圖片特徵  
使用不同濾波器會呈現不同效果  
通常是方形  
又稱為遮罩(mask)或核心(kernel)  

### 一維向量的卷積運算
基本上在重複"移動->對齊->算乘積和"  
有兩個一維向量的時候，圖像通常是比較長的(長向量)，遮罩通常是比較短的(短向量)  
以下為步驟:  
有兩個向量:A=[3,4,5] , B=[1,2,3,4,5]  
先把A的第一項對到B的第一項:  
3,4,5  
1,2,3,4,5  
接著把第一項乘以第一項，第二項乘以第二項，第三項乘以第三項  
3*1+4*2+5*3  
計算乘積和  
得26  
將這個數字放到結果向量的第一項  
  
把A的第一項對到B的第二項(下移一格):  
   3,4,5  
1,2,3,4,5  
相乘:3*2+4*3+5*4  
計算乘積和  
得38  
將這個數字放到結果向量的第三項  
  
把A的第一項對到B的第三項(再下移一格):  
     3,4,5  
1,2,3,4,5  
相乘:3*3+4*4+5*5  
計算乘積和  
得50  
將這個數字放到結果向量的第三項  
短向量的最後一個元素對到長向量的最後一個元素，運算即結束  
結果向量=26,38,50  

### 二維向量的捲積運算
有兩個矩陣:  
A=1,2,3  
     4,5,4  
     3,2,1  
B=2,0,4,7  
     9,3,6,1  
     0,3,1,2  
     5,8,8,9  
  
先把A的左上角對齊B的左上角  
相乘:1*2+2*0+3*4+  
        4*9+5*3+4*6+  
        3*0+2*3+1*1=96  
將此數字放到結果矩陣的左上  
  
把A的右上角對齊B的右上角(右移一格)  
相乘:1*0+2*4+3*7+  
        4*3+5*6+4*1+  
        3*3+2*1+1*2=88  
將此數字放到結果矩陣的右上        
  
先把A的左下角對齊B的左下角(用Z字形往下)  
相乘:1*9+2*3+3*6+  
        4*0+5*3+4*1+  
        3*2+2*8+1*8=91  
將此數字放到結果矩陣的左下  
  
先把A的右下角對齊B的右下角  
相乘:1*3+2*6+3*1+  
        4*3+5*1+4*2+  
        3*8+2*8+1*9=92  
將此數字放到結果矩陣的右下  
結果矩陣為96,88  
                  91,92  
  
### 濾波器
平滑濾波器(平均濾波器):主要用於減少雜訊、模糊化(blurring)，將遮罩所罩住的區域取算數平均輸出  
權重平均濾波器:可以自己決定每格站平均的權重  
中值濾波器:主要用於減少雜訊，將被遮罩罩住的地方取中位數當做輸出  
索伯濾波器(sobel filter):主要用於邊緣檢測，數學意義為透過離散性分差運算來計算圖像亮度梯度  

### 卷積層
通常為卷積網路的主體  
先把圖片變成RGB三個通道的矩陣(得到三個與圖片大小一樣的矩陣)->進行運算->得到特徵->送到下一層  
後面的卷積層透過上層的輸出為輸入進行運算  
輸出圖片透過一層一層的濾波，特徵會越來越明顯  
因此，多個卷積層的神經網路具備提取特徵的功能  

### 池化層
卷積層處理後，部分神經元可能特別活躍，造成特定區域的運算量增大  
壓縮卷積層輸出的特徵圖，只留下主要特徵，減少計算複雜度  
功能在於找出局部的特殊值(?)  
將圖片的RGB三通道分開->每個通道中的圖片都分成數個大小相同的區塊(每塊地向速數量相同)->每個區塊只取一個值為代表->將代表值組合成新通道->三通道重疊成一張新圖片  
池化層通常分平均池化層(以平均做代表值)、最大池化層(取最大值)，較常使用最大池化  

### 卷積神經網路中的全連接層 
可以將之前學習到的特徵向量進行轉換  
不同於卷積層，全連接層計算的值不會受特徵所在位置影響  

### 激活層
為了解決現實生活分類難以用線性分類解決的問題，在網路中加入非線性函數  
接在卷積層跟全連接層後  
作法:在每次線性運算中加入一個非線性函數運算  
1.Sigmoid(S函數):  
把值限制在0~1之間  
可理解為正規化  
2.tanH(雙取證切函數):  
把值限制在-1~1之間  
3.ReLU(線性整流函數):  
將比零小的值調整為零，比零大的直接輸出  

### 深度學習模型訓練
資料庫分成訓練集、驗證集、測試集  
訓練集:用於訓練模型學習，用來調整內部參數，直到能辨認訓練集內的圖片  
驗證集:用來調整結構，例如某隱藏層的神經元個數  
測試集:拿來考機器，檢測效果  

## 教育部隨機森林

### 名詞對照
人工智慧-最廣泛可以說是人製造出"看起來"有智慧的東西  
一次經驗會是一筆資料，稱作樣本(Instance)  
樣本需有明確答案  
可以用X、Y成對表示  
X為觀察Y為答案  
Y由X數學運算得來  
Y稱為應變量(Dependent Variable)   
X稱為自變量(Independent Variable)  
在分類問題中，Y會稱為類別(class)或標籤(label)  
在分類問題中，X則是觀察後得到的樣本特徵(feature)  
函數則稱為模型(model)  
決定模型參數的過程抽為訓練(train)  
訓練好的模型可預測未知樣本的答案(未知樣本)  

### 隨機森林
核心是決策樹(decision tree)  
"樹"可以用來做搜尋  
由樹根往下走的過程稱為走訪(tree traversal)  
一堆樹便是森林  
用決策樹當子模型的一種集成學習方式  
樹組成森林的方法:水平組合、垂直組合  
也可以混著組  
稱為集成學習(整體學習)(ensemble learnig)  

### 裝袋法(bagging)
像是投票(多數決)，集合多個彼此獨立個體的診斷，選最多人判斷的選項  
ex:你不確定你是否罹患癌症，你問一個醫生，他認為你離癌，你不確定，所以另外問了19個醫生，其中18個都說你有病，那你基本上就有病  
bootstrap aggregateing 的縮寫，中譯為引導聚集法  
bootstrap 其實是靴子後面的小  拉環，目的是不求人幫忙穿靴子，由一個資料及衍伸出大量資料集    
ex:N個樣本->訓練模型->重複N次(隨機抽取->標記->放回)->把有做過標記(包含重複標記)提出來，定義為下一個抽樣資料集  
產生一個抽樣資料及過程稱為一次過程  
抽過的放回樣本再重抽，統計上叫tsampling with replacement  
抽出不放回去再抽，叫不重複抽樣(sampling without replacement)  
bootstrap目的是為了用不同的資料集產生出不同的模型  
 
### 提升法(boosting)
要訓練第一個模型才能做第二個  
後續模型是為了補足前模型的不足之處  
自適應提升法(adaboost):  
會用調整權重的方式減少錯誤率  
N個樣本->訓練第一個子模型->假設準確率9成->增加那N/10個樣本(判斷錯誤)的權重:可以視為把錯誤樣本重複一遍加入原始訓練資料集(資料集內會有1.1*N個資料)->訓練第二個子模型
梯度提升法(GBDT)
只有訓練時需要是垂直，使用時不需要

### 堆疊法
把裝拜法投票的過程也用機器學習來做，找出最準的模型  
首先產生m個彼此不關聯的模型->把m個模型的輸出當成新模型的輸入->根據輸入找特徵  
實務上做到第二層就差不多了  

### 裝袋森林
把裝袋法套到決策樹上  
除了樣本抽樣，還會針對特徵集進行抽樣  
有N個樣本，有M個決策樹，產生一個集成模型  
每個決策樹先重複抽樣N次(bagging)->產生抽樣後資料集->進行決策樹訓練->產生決策樹模型->重複M次(產生M個模型)->各個決策樹投票  
決策樹基本不用超過500(除非資料量太多)  





